<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Wen Qiu</title>

  <meta name="author" content="Wen Qiu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Wen Qiu (邱雯)
                  </p>

                  <p>
                    I hold a master's degree from <a href="https://www.ahut.edu.cn/">Anhui
                      University of Technology</a>, and now is a Ph.D. candidate at <a href="https://www.kitami-it.ac.jp/en/">Kitami
                      Institute of Technology(Japan)</a>. My research interests include Deep Reinforcement Learning, Game Theory. 
                      Application areas in emergency communication networks. Now I'm a part
                      of a Chinese open source organization <a href="https://datawhale.club/home">Datawhale</a>.
                  </p>

                  <!-- <p>
                    In my professional capacity, I interned as a Research Engineer at Baidu in Beijing, guided by
                    Xiaomin Yuan from June to September 2021. Subsequently, I served as a Reinforcement Learning
                    Algorithms Engineer at <a href="https://www.inspirai.com/">InspirAI</a> from June 2022 to May 2023,
                    where I applied my academic expertise to
                    practical AI applications.

                  </p> -->

                  <p style="text-align:center">
                    <a href="mailto:clorisqiu1@gmail.com">Email</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com/citations?user=KeR9g2YAAAAJ&hl=zh-CN">Scholar</a>
                    &nbsp;/&nbsp;
                    <!-- <a href="https://github.com/clorisqiu1">Github</a> &nbsp;/&nbsp; -->
                    <!-- <a href="https://www.zhihu.com/people/zhiqianghe">Zhihu</a> &nbsp;/&nbsp; -->

                    <a href="https://blog.csdn.net/weixin_41794514?spm=1010.2135.3001.5343">CSDN</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/clorisqiu.jpg"><img
                      style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo"
                      src="images/clorisqiu.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Experience</h2>
                  <!-- <p>
                    Between June 2022 and May 2023, I served as a Reinforcement Learning Algorithms Engineer at
                    InspirAI. My team and I proposed and optimized a universal AI modeling paradigm for card games,
                    successfully deploying it in games like Hearthstone, Dou Dizhu (defeating professional players), and
                    Guan Dan. Notably, we created a Doudizhu AI, which was launched on the <a
                      href="https://www.taptap.cn/moment/356764971171842277">Taptop platform</a>.
                  </p>

                  <p>
                    In the summer of 2021, I had the opportunity to intern as a Research Engineer at Baidu AI Cloud in
                    Beijing, collaborating closely with Xiaomin Yuan. During this time, we developed an innovative
                    multi-agent cooperative adversarial algorithm, which we termed Expert Data-Assisted Multi-Agent
                    Proximal Policy Optimization (EDA-MAPPO). Our work culminated in the release of a performance video
                    showcasing our algorithm, which is now available on <a
                      href="https://www.bilibili.com/video/BV1LV411p7KD/?spm_id_from=333.999.0.0&vd_source=d8ab7686ea514acb6635faa5d2227d61">Bilibili</a>
                    and the accompanying <a href="https://github.com/tinyzqh/light_mappo">source code</a>.
                  </p> -->

                </td>
              </tr>
            </tbody>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Publication / Preprint</h2>
                </td>

              </tr>
            </tbody>
          </table>


          <!-- <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <a href="https://www.mdpi.com/1999-4893/11/5/65">
                  <span class="papertitle">Control Strategy of Speed Servo Systems Based on Deep Reinforcement
                    Learning
                  </span>
                </a>
                <a href="https://github.com/tinyzqh/control-of-jump-systems-based-on-reinforcement-learning">Code</a>
                <br>
                <a href="https://yzw.tzc.edu.cn/info/1021/1084.htm">Pengzhan Chen</a>,
                <strong>Zhiqiang He</strong>,
                <a>Chuanxi Chen</a>,
                <a>Jiahong Xu</a>,
                <br>
                <em>Algorithms 11, no. 5: 65.<em>, 2018,
                    <br>
              </td>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320322001492">
                  <span class="papertitle">Erlang planning network: An iterative model-based reinforcement learning with
                    multi-perspective
                  </span>
                </a>
                <a href="https://github.com/tinyzqh/Erlang-planning-network">Code</a>
                <br>
                <a href="http://faculty.neu.edu.cn/wangjiao/zh_CN/zhym/75393/list/index.htm">Jiao Wang</a>,
                <a>Lemin Zhang</a>,
                <strong>Zhiqiang He</strong>,
                <a>Can Zhu</a>,
                <a>Zihui Zhao</a>,
                <br>
                <em>Pattern Recognition, 128: 108668.<em>, 2022,
                    <br>
              </td>
            </tbody>
          </table> -->





          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    <a href="https://github.com/jonbarron/jonbarron_website">Credits</a>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>


        </td>
      </tr>
  </table>
</body>

</html>